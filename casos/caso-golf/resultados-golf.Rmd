---
title: "Modelos para *putts* de golf"
output:
  pdf_document: default
  html_document: default
bibliography: ../../referencias/referencias.bib
---

Este caso está basado en @GelmanNolan y @GolfCase. A lo largo de este ejemplo
ilustraremos los pasos de un flujo de trabajo para modelado Bayesiano.
En paralelo discutiremos los conceptos clave para guiar el desarrollo de modelos
y este caso servirá como breve introudcción al lenguaje de programación
probabilistica `Stan` [@stan]. 
En particular usaremos el flujo de trabajo bayesiano tomado del documento de
@BetancourtCase y posteriormente refinado en el artículo @bayesworkflow.


```{r setup, include=FALSE, message=FALSE}
library(cmdstanr)
library(posterior)
library(bayesplot)
library(tidyverse)
library(patchwork)
source("../../funciones-auxiliares/simular_resumenes.R")

register_knitr_engine(override = FALSE)

print_file <- function(file) {
  cat(paste(readLines(file), "\n", sep=""), sep="")
}

knitr::opts_chunk$set(echo = TRUE, cache = TRUE, comment = "",
                      fig.align = "center", out.width = "75%", 
                      message = FALSE, warning = FALSE)

comma <- function(x) format(x, digits = 2, big.mark = ",")
remove.warnings <- function(){assign("last.warning", NULL, envir = baseenv())}
theme_set(theme_linedraw())
sin_lineas <- theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
```

## Definición del problema

Queremos entender y modelar la probabilidad de éxito de *putts* de Golf
(*putts*: tiros relativamente cerca del hoyo que buscan que la pelota ruede al
hoyo o muy cerca de él), y cómo depende el éxito de la distancia del tiro. Como
conclusiones quisiéramos inferir qué tan precisos son los profesionales en sus
tiros.

Para este estudio tenemos disponible el siguiente conjunto de datos @GelmanNolan. 

**Definición.** El espacio de observaciones que esperaríamos son del tipo $(x, y)$
donde $x$ es la distancia del *putt* y $y$ indica si se logró o no. Sin embargo,
los datos que tenemos son agregados: para cada distancia aproximada $x_j$
tendremos un conteo de intentos $n_j$ y éxitos $y_j$ sobre los tiros de los
jugadores profesionales. En total las distancias han sido redondeadas y
obtenemos $J = 19$ distancias distintas.


```{r, echo = FALSE, message= FALSE}
datos <- read_delim("datos/golf.csv", delim = " ")
datos <- datos %>% 
  mutate(x = round(30.48  * x, 0), 
         se = sqrt((y/n)*(1-y/n)/n))

g_datos <- datos %>% 
  ggplot(aes(x = x, y = y/n)) + 
    geom_linerange(aes(ymin = y/n - 2 * se, ymax = y/n + 2*se)) + 
    geom_point(colour = "steelblue", alpha = 1.) + 
    ylim(c(0,1)) + xlab("Distancia (cm)") + ylab("Tasa de éxito") + 
    ggtitle("Datos sobre putts en golf profesional") + sin_lineas

g_datos
```

Los puntos muestran las tasas de éxito para cada intento de tiro como función
de la distancia a la meta. Las barras indican intervalos de confianza al 95\%
utilizando el error estándar clásico $\sqrt{\hat p_j (1- \hat p_j)/n_j},$ donde
$\hat p_j = y_j / n_j.$

### Modelo logístico 

Un primer intento es modelar la probabilidad de éxito a través de una regresión
logística.
$$y_j \sim \mathsf{Binomial}\left(n_j, \text{logit}^{-1}(a + b x_j)\right),$$
para cada $j = 1, \ldots, J.$ Este modelo lo escribimos en `Stan` como sigue 
```{r, echo=FALSE, message=FALSE, warning = FALSE}
print_file("modelos/regresion_logistica.stan")
```
Notemos que no hemos especificado una distribución inicial explícita para
nuestros parámetros. Por default `Stan` está incorporando una distribución
*plana* en todo el espacio $(a,b) \in \mathbb{R}^2.$ Podríamos debatir si esto
es aceptable y las consecuencias de incluir una distribución inicial de esta
naturaleza. 

Compilamos el modelo para poder utilizarlo. 
```{r}
ruta <- file.path("modelos/regresion_logistica.stan")
modelo <- cmdstan_model(ruta)
```
Ahora podemos ajustar a los datos observados. `Stan` en general recibe los datos
como una lista con nombres. Utilizando nuestra función `ajustar_modelo` podemos
simular 1,000 iteraciones de la posterior bajo muestreo utilizando una variante
`HMC` llamada `NUTS` (*No U-Turn Sampler*).

```{r, message=FALSE, warning=FALSE}
data_list <- c(datos, list("J" = nrow(datos)))
ajuste <- ajustar_modelo(modelo, data_list)
```

Parece que el muestreador no tuvo problemas en correr y podemos checarlo con la
función de
[diagnóstico](https://mc-stan.org/docs/2_25/cmdstan-guide/diagnose.html). Más
adelante estudiaremos los diágnósticos que utilizamos para evaluar modelos.

```{r}
ajuste$cmdstan_diagnose()
```

Más aún, podemos pedir el resumen del ajuste donde leemos estadisticas de
interes como media, mediana, desviación estándar e intervalos de credibilidad
del 90\%.
```{r}
ajuste$summary(c("a", "b"))
```
Podemos extraer las muestras de cada parámetro por medio de la librería
`posterior`
```{r}
muestras <- tibble(posterior::as_draws_df(ajuste$draws(c("a", "b"))))
```
y utilizar distintos diagnósticos gráficos como
```{r}
muestras %>% 
  pivot_longer(cols = c(a, b), names_to = 'parameter') %>% 
  mutate(Chain = as.factor(.chain)) %>% 
  ggplot(aes(x = .iteration, y = value)) + 
    geom_line(aes(group = .chain, color = Chain)) + 
    facet_wrap(~parameter, ncol = 1, scales = 'free', strip.position="right") + 
    scale_color_viridis_d(option = 'plasma')+ sin_lineas
```

De igual forma podríamos calcular el máximo de la posterior (que en este caso
coincide con el MLE) mediante
```{r, message = FALSE, warning = FALSE}
params_map <- modelo$optimize(data = data_list, seed = 108)
params_map <- params_map$summary() %>% 
  pivot_wider(values_from = estimate, names_from = variable)
params_map
```

Salvo algunos mensajes de error en la inicialización en la optimización parece
ser que tenemos un modelo bien comportado. Podríamos explorar un gráfico de
dispersión para visualizar la correlación posterior de nuestros parámetros y
ubicar el valor que maximiza la pseudo-posterior.
```{r, warning = FALSE}
muestras %>% 
  ggplot(aes(x = a, y = b)) + 
  geom_point() + 
  geom_point(data = params_map, aes(x = a, y = b),
             color = 'salmon', shape = 4, stroke = 2) + 
  ggtitle('Muestras de la posterior')+ sin_lineas
```

```{r, cache = TRUE}
logit <- qlogis
invlogit <- plogis

modelo_logistico <- function(a, b){
  x <- seq(0, 1.1 * max(datos$x), length.out = 50)
  tibble(x = x, y = invlogit(a *x + b))
}

curvas_regresion <- muestras %>% 
  mutate(curva = map2(a, b, modelo_logistico)) %>% 
  select(-a, -b) %>% 
  unnest(curva) %>% 
  group_by(x) %>% 
  summarise(mediana = median(y), 
            q_low = quantile(y, .005), 
            q_hi = quantile(y, .995), 
            .groups = 'drop')

g_logistico <- datos %>% 
  ggplot(aes(x = x, y = y/n)) + 
    geom_linerange(aes(ymin = y/n - 2 * se, ymax = y/n + 2*se)) + 
    geom_point(colour = "steelblue", alpha = 1.) + 
    geom_line(data = curvas_regresion, aes(x = x, y = mediana)) +
    geom_ribbon(data = curvas_regresion, aes(x = x, ymin = q_low, ymax = q_hi), 
                alpha = .2, inherit.aes = FALSE) +
    ylim(c(0,1)) + xlab("Distancia (cm)") + ylab("Tasa de éxito") + 
    ggtitle("Regresion logística ajustada")+ sin_lineas

g_logistico

muestras_logistico <- muestras
```

La línea solida representa la mediana de la curva de regresión calculada entre
las muestras de la posterior obtenidas. La región sombreada corresponde a la
banda del 99\% de credibilidad calculada a partir del mismo conjunto de
muestras.

El modelo es razonable, en el sentido de que los parámetros tienen los valores
que esperaríamos. La pendiente del modelo de regresión logística es negativa, lo
cual interpretamos como la falta de precisión del tirador mientras mas alejado
del hoyo. Mientras que para el caso base ($x = 0$) el modelo da una probabilidad
de éxito relativamente alta.

En las siguientes secciones ilustraremos el procedimiento para complementar el
modelo.

### Análisis conceptual

Podemos pensar en cada intento que hace un golfista como una prueba
independiente que puede resultar en éxito o fracaso. El modelo anterior estable
la probabilidad de éxito como una función no lineal de la distancia.

El problema es considerablemente complicado conceptualmente (@HolmesGolf,
@PennerPutting) si consideramos todas las fuentes de variación: ángulo de tiro,
potencia de tiro, declive en greens y así sucesivamente. Los supuestos que
debemos criticar son:

Seguiremos haciendo la simplificación de superficie plana, pero consideramos
dos parámetros para el tiro con distintas condiciones de éxito:

1. El ángulo del tiro.
2. La velocidad con la que la pelota llega (o no llega) al hoyo.

Los radios de una pelota de golf y el hoyo (en centímetros) es de

```{r, message = FALSE, warning = FALSE}
radios <- tibble(pelota = (1.68/2 * 2.54) %>% round(1), 
                  hoyo  = (4.25/2 * 2.54) %>% round(1))

radios
```

Supondremos por el momento que los *greens* de golf (áreas cerca del hoyo) 
son perfectamente planos (lo cual no es cierto, pero refinaremos después),
de modo que el éxito depende de:

1. Tirar la pelota con un ángulo suficientemente cercano a cero con respecto a
la línea que va del centro de la pelota al centro del hoyo.
2. Tirar la pelota con una velocidad suficiente para que llegue al hoyo pero no
tan alta que vuele por encima del hoyo.

Mejores datos de los tipos de fallo sería útil, pero por el momento no los
tenemos disponibles.

#### Ángulo de tiro

Supongamos que la distancia del centro de la pelota al centro del hoyo es $x.$ 
Idealmente ésta es la trayectoria que el golfista tendría que ejecutar. Sin
embargo, el tiro puede ser inexacto y denotamos por $\theta$ el ángulo del tiro
realizado. El tiro es exitoso cuando el angulo de tiro satisface
$$|\theta| < \tan^{-1}\left(\frac{R - r}{x}\right).$$
Incorporamos un esquema de esta situación a continuación. 

```{r, echo = FALSE, fig.cap="Esquema de ángulo de tiro", warning = FALSE}
knitr::include_graphics("imagenes/esquema-tiro.png")
```


**Observación.** Aqui hemos hecho un supuesto importante. La distancia reportada
en los datos, la cual hemos denotado por $x,$ es la distancia entre el centro de
la pelota y el centro del hoyo. ¿Cómo cambiaría nuestra condición de éxito si
suponemos que la distancia que viaja la pelota es la registrada, es decir si
ésta correspondiera a $x'$ en nuestro esquema?

En particular para nuestro problema, la condición de éxito es
$$|\theta| < \tan^{-1}\left( \frac{3.3}{x} \right)$$

Mejores golfistas tendrán mejor control sobre $\theta$, y conforme
$x$ es más grande, la probabilidad de tener éxito baja:

```{r, warning = FALSE, message = FALSE}
tibble(x = seq(10, 1500, 1)) %>% 
  mutate(theta = (180 / pi) * atan(3.3 / x)) %>% 
ggplot(aes(x, theta)) + geom_line() +
  xlab("Distancia (cm)") +
  ylab(expression(paste("Desviación máxima |", theta,"|"))) +
  labs(subtitle = "Desviación máxima permitida para tener éxito a distintas distancias") +
  scale_y_log10()+ sin_lineas
```

**Observación.** Esta curva puede variar dependiendo del jugador, pero vamos a
modelar el conjunto de tiros de jugadores profesionales. Suponemos homogeneidad,
misma que podríamos checar con datos desagregados por jugador. Estos datos
podrían tener sobre-representación de tiradores malos (pues quizá hacen más
tiros).

Para modelar $\theta$ de manera probabilista asumimos una distribución Gaussiana
con desviación estándar $\sigma.$ Este modelo codifica nuestra suposición de que
los jugadores en promedio tirarán de manera recta, sin embagro puede haber
diversos factores que afectarán este resultado.

Siguiendo esta distribución, la probabilidad de éxito se calcula como 
$$\mathbb{P}\left\{\,  |\theta| <  \tan^{-1}\left( \frac{R - r}{x} \right)\right\} = 2 \, \Phi\left[ \frac{\tan^{-1}((R - r)/x)}{\sigma}\right] - 1,$$
donde $\Phi$ es la función de acumulación de una Normal estándar.

La figura siguiente muestra las curvas de probabilidad para distintos valores
de $\sigma$ para distintos valores de la distancia al hoyo. 

```{r, echo = FALSE}
curva_angulo <- function(sigma){
  x <- seq(0, 650, by = .5)
  R.diff <- radios %>% summarise(diff = hoyo - pelota) %>% pull(diff)
  tibble(x = x, y = 2 * pnorm( (180/pi) * atan(R.diff/x)/sigma) - 1)
}

tibble(sigma = 2**seq(0,5)) %>% 
  mutate(curva = map(sigma, curva_angulo), 
         Sigma = as.factor(sigma)) %>% 
  unnest(curva) %>% 
  ggplot(aes(x = x, y = y)) + 
    geom_line(aes(group = sigma, color = Sigma)) + 
    scale_color_viridis_d() + ylim(c(0,1)) + xlab("Distancia (cm)") + ylab("Probabilidad de éxito") + 
    ggtitle(expression(paste("Probabilidad de éxito para diferentes valores de ", sigma," (en grados ", ~degree, ").")))+ sin_lineas
```

La curva mas alta de la gráfica corresponde a una desviación estándar de
$1^\circ,$ que implica que un jugoador de golf tendrá en promedio una
probabilidad cercana a $25\%$ cuando se encuentre a 6 metros de distancia;
alrededor de $60\%$ cuando se encuentre a 2 metros, $90\%$ a un metro, etc.

Ahora veamos las distintas realizaciones de tiros a 1 metro de distancia bajo
distintos valores de $\sigma.$

```{r, out.width = "95%", fig.height = 3}
simula_tiros <- function(sigma){
  distancia  <- 1
  n_muestras <- 250
  angulos_tiro <- (pi/180) * rnorm(n_muestras, 0, sigma)
  tibble(x = distancia * cos(angulos_tiro), 
         y = distancia * sin(angulos_tiro))
}

tibble(sigma_grados = c(1, 8, 32, 64)) %>% 
  mutate(tiros = map(sigma_grados, simula_tiros)) %>% 
  unnest(tiros) %>% 
  ggplot(aes(x = x, y = y)) + 
    geom_point() +
    geom_segment(aes(x = 0, y = 0, xend = x, yend = y), alpha = .1) + 
    geom_point(aes(x = 0, y = 0), color = 'red') + 
    facet_wrap(~sigma_grados, ncol = 4) + 
    ylab("") + xlab("") + ggtitle("Posiciones finales de tiro")+ sin_lineas
  
```

Notamos que los tiros en general tienen un buen comportamiento. Posiblemente
valores de tiros con una desviación de $60^\circ$ dan lugar a tiros que no
tienen sentido. Este punto lo veremos más adelante en caso de que tengamos que
refinar. Por el momento, el modelo queda como sigue
\begin{align}
p_j & =  2 \, \Phi\left( \frac{\tan^{-1}((R - r)/x_j)}{\sigma}\right) - 1,\\
y_j &\sim \mathsf{Binomial}\left(n_j, p_j\right), 
\end{align}
para $j = 1, \ldots, J.$

El modelo en `Stan` lo escribimos como sigue
```{r, echo=FALSE, message=FALSE, warning = FALSE}
print_file("modelos/modelo_angulo.stan")
```

**Observación.** Seguimos sin utilizar una distribución a priori para los
parámetros del modelo. En este caso, el model requiere de especificar una
distribución para la desviación estándar del ángulo de tiro, $\sigma.$ Por el
momento se le ha asignado una distribucion *plana* en $\mathbb{R}^+.$

```{r}
data_list$r = radios$pelota
data_list$R = radios$hoyo

ruta <- file.path("modelos/modelo_angulo.stan")
modelo <- cmdstan_model(ruta)

ajuste <- ajustar_modelo(modelo, data_list)

ajuste$cmdstan_diagnose()

ajuste$summary(c("sigma", "sigma_degrees"))
```

```{r, fig.height = 2}
muestras <- tibble(posterior::as_draws_df(ajuste$draws(c("sigma", "sigma_degrees"))))

muestras %>% 
  select(-sigma_degrees) %>% 
  pivot_longer(cols = c(sigma), names_to = 'parameter') %>% 
  mutate(Chain = as.factor(.chain)) %>% 
  ggplot(aes(x = .iteration, y = value)) + 
    geom_line(aes(group = .chain, color = Chain)) + 
    facet_wrap(~parameter, ncol = 1, scales = 'free', strip.position="right") + 
    scale_color_viridis_d(option = 'plasma')+ sin_lineas
```

```{r, out.width = "99%", fig.height = 3}
modelo_angulo <- function(sigma_radianes){
  x <- seq(0, 1.1 * max(datos$x), length.out = 50)
  R.diff <- radios %>% summarise(diff = hoyo - pelota) %>% pull(diff)
  tibble(x = x, y = 2 * pnorm( atan(R.diff/x)/sigma_radianes) - 1)
}

curvas_regresion <- muestras %>% 
  mutate(curva = map(sigma, modelo_angulo)) %>% 
  select(-sigma_degrees, -sigma) %>% 
  unnest(curva) %>% 
  group_by(x) %>% 
  summarise(mediana = median(y), 
            q_low = quantile(y, .005), 
            q_hi = quantile(y, .995), 
            .groups = 'drop')

g_angulo <- datos %>% 
  ggplot(aes(x = x, y = y/n)) + 
    geom_linerange(aes(ymin = y/n - 2 * se, ymax = y/n + 2*se)) + 
    geom_point(colour = "steelblue", alpha = 1.) + 
    geom_line(data = curvas_regresion, aes(x = x, y = mediana)) +
    geom_ribbon(data = curvas_regresion, aes(x = x, ymin = q_low, ymax = q_hi), 
                alpha = .2, inherit.aes = FALSE) +
    ylim(c(0,1)) + xlab("Distancia (cm)") + ylab("Tasa de éxito") + 
    ggtitle("Modelo con ángulo de tiro")+ sin_lineas

g_logistico + g_angulo
```
Por el momento parece que el modelo está haciendo un muy buen trabajo. Parece
ser que no es necesario incluir información previa en los parámetros. 

#### Nuevo conjunto de datos

Después de algunos años se consiguieron mas registros. En particular, el
profesor Broadie fue el que brindo dichos datos. La cantidad es impresionante, 
basta con observar la dispersión de la probabilidad de éxito bajo el supuesto
normal. Los intervalos de confianza son casi imperceptibles.

```{r, echo = FALSE}
datos_bkp <- datos
```


```{r, message = FALSE, echo = FALSE}
datos_grande <- read_delim("datos/golf_grande.csv", delim = "\t")
datos_grande <- datos_grande %>% 
  mutate(x = dis * 30.48, n = count, y = exitos, se = sqrt((y/n)*(1-y/n)/n), fuente = "Nuevos") %>% 
  select(x, n, y, se, fuente)

datos <- rbind(datos %>% mutate(fuente = "Original"), datos_grande)
datos <- datos %>% mutate(fuente = as.factor(fuente))

curvas_regresion <- muestras %>% 
  mutate(curva = map(sigma, modelo_angulo)) %>% 
  select(-sigma_degrees, -sigma) %>% 
  unnest(curva) %>% 
  group_by(x) %>% 
  summarise(mediana = median(y), 
            q_low = quantile(y, .005), 
            q_hi = quantile(y, .995), 
            .groups = 'drop')

datos %>% 
  ggplot(aes(x = x, y = y/n)) + 
    geom_linerange(aes(ymin = y/n - 2 * se, ymax = y/n + 2 * se)) + 
    geom_point(aes(colour = fuente), alpha = 1.) +
    geom_line(data = curvas_regresion, aes(x = x, y = mediana)) +
    geom_ribbon(data = curvas_regresion, aes(x = x, ymin = q_low, ymax = q_hi),
                alpha = .2, inherit.aes = FALSE) +
    ylim(c(0,1)) + xlab("Distancia (cm)") + ylab("Tasa de éxito") +
    ggtitle("Modelo con ángulo de tiro")+ sin_lineas

```

#### Velocidad final

Para poder hacer un tiro exitoso no sólo es necesario controlar el ángulo de
tiro. También es importante tirar con la fuerza suficiente. Siguiendo
[@PennerPutting], existe un rango de velocidades iniciales que determinan la
condición de éxito.

- La condición de éxito en un tiro recto es que la velocidad final $v_f$ (en
metros por segundo) de la pelota cumpla con las siguientes condiciones
$$0 < v_f < 1.63.$$
- Por otro lado, la aceleración de la pelota al rodar en el *green* satisface
$$a = \left(\frac{10}{7}\right) \, {\rho_r}\, g.$$
donde $\rho_r = \rho/r,$ y $\rho$ depende de la superficie donde rueda la
pelota, $r$ es el radio de la pelota y $g$ la fuerza de gravedad. Datos
experimentales indican que la media en *greens* es de $\rho_r = 0.131,$ con un
rango de 0.065 a 0.196. De momento, tomaremos $\rho_r = 0.131.$


La velocidad final de la pelota, en términos de la velocidad inicial, utiliza 
la aceleración en el *green,* lo cual da la siguiente cadenca de igualdades
$$v_f^2 = v_0^2 - \left(\frac{10}{7}\right) \, {\rho_r}\, g \, x_m = v_0^2 - \left(\frac{10}{7}\right) (0.131) \, (9.81) \, x_m = v_0^2 -  1.835871 \, x_m$$
donde $x_m$ es la distancia de la pelota al hoyo en metros. Ahora, podemos
despejar para calcular las condiciones de éxito sobre la velocidad inicial $v_0$
$$c\,  x_m < v_0^2 < (1.63)^2 + c \,  x_m,$$
donde $c = 1.835871$. La condición de éxito se puede escribir en términos de la 
distancia de la pelota al hoyo. Es decir podemos escribir 
$$u \in \left [\, x, \, x + 145 \,  \right],$$
donde $u = v_0^2/c \times 100$ es la distancia en centímetros que la pelota
viajaría si no hubiera un hoyo en medio. Esto quiere decir que la pelota debe
ser lanzada con fuerza suficiente para alcanzar el hoyo pero no tanta como para
sobrepasarse.

Ahora, siguiendo las recomendaciones de Mark Broadie en @GolfCase. Suponemos que
los golfistas tienden a tirar con fuerza suficiente para pasarse del hoyo por un
pie (30.48 cm), sin embargo la fuerza tiene un error multiplicativo. La
intuición es que errores de la misma magnitud afectan en proporción a la
distancia de tiro.

La distancia que recorre la pelota esta definida como 
$$ u = (x + 30.48) \cdot (1 + \varepsilon),$$
donde
$$ \varepsilon \sim \mathsf{N}(0, \sigma^2_f),$$
y hemos utilizado la notación $\sigma^2_f$ para hace énfasis en el error
asociado a la fuerza de tiro. Esto implica que 
$$u \sim \mathsf{N}\left(x + 30.48, (x + 30.48)^2  \sigma^2_f\right),$$
y por la tanto el éxito debido a la fuerza de tiro ---la condición $u \in \left
[\, x, \, x + 145 \,  \right]$--- tiene probabilidad de éxito igual a
$$\Phi\left(\frac{114.52}{(x + 30.48)  \sigma_f}\right) - \Phi\left(\frac{-30.48}{(x + 30.48)  \sigma_f}\right),$$
que es un evento que asumimos independiente del ángulo de tiro.


Para finalizar, utilizamos las condiciones de éxito que definen ambos eventos
que asumimos independientes, el ángulo de tiro y la fuerza. Por lo tanto, el
modelo lo escribimos como
\begin{align}
p_j^u & = \Phi\left(\frac{114.52}{(x + 30.48)  \sigma_f}\right) - \Phi\left(\frac{-30.48}{(x + 30.48)  \sigma_f}\right), \\
p_j^\theta & =  2 \, \Phi\left( \frac{\tan^{-1}((R - r)/x_j)}{\sigma_\theta}\right) - 1,\\
p_j & = p_j^u \cdot p_j^\theta \\
y_j & \sim \mathsf{Binomial}\left(n_j, p_j\right), 
\end{align}
para $j = 1, \ldots, J.$

El modelo en `Stan` es el siguiente 
```{r, echo=FALSE, message=FALSE, warning = FALSE}
print_file("modelos/modelo_angulo_fuerza.stan")
```



```{r leer datos nuevos}
# datos <- datos %>% filter(fuente == 1)
data_new <- list(x = datos$x, n = datos$n, y = datos$y, J = nrow(datos), 
                 r = radios$pelota, R = radios$hoyo, 
                 distance_tolerance = 4.5 * 30.48,# 145,
                 overshot = 30.48)
```

```{r ajuster modelo angulo fuerza}
ruta <- file.path("modelos/modelo_angulo_fuerza.stan")
modelo <- cmdstan_model(ruta)

ajuste <- ajustar_modelo(modelo, data_new)

ajuste$cmdstan_diagnose()

ajuste$summary(c("sigma_angle", "sigma_degrees", "sigma_force"))
```

```{r, echo = FALSE}
modelo_angulo_fuerza <- function(sigma_radianes, sigma_fuerza){
  x <- seq(0, 1.1 * max(datos$x), length.out = 50)
  R.diff <- radios %>% summarise(diff = hoyo - pelota) %>% pull(diff)
  tibble(x = x, 
         p_angulo = 2 * pnorm( atan(R.diff/x)/sigma_radianes) - 1, 
         p_fuerza = pnorm((data_new$distance_tolerance - data_new$overshot) / ((x + data_new$overshot)*sigma_fuerza)) - 
           pnorm((- data_new$overshot) / ((x + data_new$overshot)*sigma_fuerza)), 
         y = p_angulo * p_fuerza) %>% 
    select(x, y)
}

muestras <- tibble(posterior::as_draws_df(ajuste$draws(c("sigma_angle", "sigma_force"))))

curvas_regresion <- muestras %>% 
  mutate(curva = map2(sigma_angle, sigma_force, modelo_angulo_fuerza)) %>% 
  select(-sigma_angle, -sigma_force) %>% 
  unnest(curva) %>% 
  group_by(x) %>% 
  summarise(mediana = median(y), 
            q_low = quantile(y, .005), 
            q_hi = quantile(y, .995), 
            .groups = 'drop')

datos %>% 
  ggplot(aes(x = x, y = y/n)) + 
    geom_linerange(aes(ymin = y/n - 2 * se, ymax = y/n + 2 * se)) + 
    geom_point(aes(colour = fuente), alpha = 1.) +
    geom_line(data = curvas_regresion, aes(x = x, y = mediana)) +
    geom_ribbon(data = curvas_regresion, aes(x = x, ymin = q_low, ymax = q_hi),
                alpha = .2, inherit.aes = FALSE) +
    ylim(c(0,1)) + xlab("Distancia (cm)") + ylab("Tasa de éxito") +
    ggtitle("Modelo con ángulo de tiro y fuerza")+ sin_lineas
```

Al explorar los residuales encontramos que parece haber cierto patrón. Mas aún,
el modelo parece estar *muy* seguro de los valores esperados de probabilidad de
éxito ---lo cual podemos apreciar al incorporar los intervalos de probabilidad
de los residuales que se calculan de las muestras. Esto se puede deber a que el
número elevado de registros que la nueva base de datos provee. 


```{r, echo = FALSE, message = FALSE, warning = FALSE}
muestras <- tibble(posterior::as_draws_df(ajuste$draws(c("residual"))))
medias <- muestras %>% 
  pivot_longer(cols = starts_with("residual"), names_to = 'parameters', values_to = 'residuals') %>% 
  group_by(parameters) %>% 
  summarise(media = mean(residuals), 
            q_lo = quantile(residuals, 0.05),
            q_hi = quantile(residuals, 0.95), groups = 'drop') %>% 
  mutate(cadena = str_replace_all(parameters, "\\[|\\]", "_")) %>% 
  separate(cadena, into = c("sufijo", "variable"), sep = "_", convert = TRUE) %>% 
  select(media, variable, q_lo, q_hi)

datos %>% 
  mutate(variable = seq(1, nrow(datos))) %>% 
  full_join(medias) %>% 
  ggplot(aes(x = x, y = media)) + 
    geom_linerange(aes(x = x, ymin = q_lo, ymax = q_hi)) + 
    geom_point(aes(color = fuente)) + 
    geom_hline(yintercept = 0, linetype = 'dashed') + 
    ylab('Residuales del modelo ajustado') + 
    xlab('Distancia (cm)') + 
    ggtitle("Modelo con angulo y fuerza de tiro.")+ sin_lineas
```
En este punto la incertidumbre tan baja se puede deber a efectos latentes en los
datos, como error de medición, o a una mala especificación del modelo. En
particular, la proporción de éxitos a tan corta distancia hace que el modelo
Binomial sobreajuste a éstos. Podríamos incorporar un modelo Binomial-Negativo
para considerar un modelo capaz de trabajar con una proporción tan alta de
éxitos.

Alternativamente, podríamos ajustar sólo en los datos nuevos. Pero no tenemos
alguna justificación específica para descartar los que ya teníamos. Por lo
pronto usaremos ambos conjuntos sin distinción.

Una estrategia es incorporar una aproximación continua a las proporciones
reportadas, misma que podemos utilizar para incorporar un error de medición
latente. El modelo queda especificado como
\begin{align}
p_j^u & = \Phi\left(\frac{114.52}{(x + 30.48)  \sigma_f}\right) - \Phi\left(\frac{-30.48}{(x + 30.48)  \sigma_f}\right), \\
p_j^\theta & =  2 \, \Phi\left( \frac{\tan^{-1}((R - r)/x_j)}{\sigma_\theta}\right) - 1,\\
p_j & = p_j^u \cdot p_j^\theta \\
\frac{y_j}{n_j} &\sim \mathsf{N}\left( p_j, \frac{p_j (1 - p_j)}{n_j} + \sigma^2_{\textsf{obs}} \right), 
\end{align}
para $j = 1, \ldots, J.$

Por otro lado, el modelo en `Stan` no cambia mucho y se vuelve un poco mas
flexible. Lo cual especificamos en el bloque de modelo
```{bash, echo = FALSE}
sed -n '/^model/,/\}/p' modelos/modelo_angulo_fuerza_normal_plano.stan
```

Podríamos ajustar sin distribución previa como lo hemos hecho antes, pero 
en este caso si tenemos problemas serios en el ajuste. 

```{r}
ruta <- file.path("modelos/modelo_angulo_fuerza_normal_plano.stan")
modelo <- cmdstan_model(ruta)

ajuste <- ajustar_modelo(modelo, data_new, iter_sampling = 1000)

ajuste$cmdstan_diagnose()
```

Podemos incorporar información *débil* en los parametros de escala, esto es por
medio de normales truncadas en la región positiva. El modelo completo sería
\begin{align}
\sigma^2 &\sim \mathsf{N}^+(0, 1) \\
p_j^u & = \Phi\left(\frac{114.52}{(x + 30.48)  \sigma_f}\right) - \Phi\left(\frac{-30.48}{(x + 30.48)  \sigma_f}\right), \\
p_j^\theta & =  2 \, \Phi\left( \frac{\tan^{-1}((R - r)/x_j)}{\sigma_\theta}\right) - 1,\\
p_j & = p_j^u \cdot p_j^\theta, \\
\frac{y_j}{n_j} &\sim \mathsf{N}\left( p_j, \frac{p_j (1 - p_j)}{n_j} + \sigma^2_{\textsf{obs}} \right), 
\end{align}
para $j = 1, \ldots, J,$ donde $\sigma^2 = (\sigma^2_{\textsf{obs}}, \sigma^2_\theta, \sigma^2_f)$.


```{r}
ruta <- file.path("modelos/modelo_angulo_fuerza_normal.stan")
modelo <- cmdstan_model(ruta)

ajuste <- ajustar_modelo(modelo, data_new, iter_sampling = 4000)

ajuste$cmdstan_diagnose()

ajuste$summary(c("sigma_angle", "sigma_degrees", "sigma_force", "sigma_obs"))
```

Los parámetros estimados los interpretamos como sigue: 

- $\sigma_\theta$ tiene un valor cercano a 0.015 que corresponde a
$\sigma_{\textsf{grados}} = 0.8.$ De acuerdo a los datos obtenidos los jugadores
de golf cometen errores de ángulo de *casi* un $1^\circ.$ Si comparamos este
valor con el de modelos anteriores podemos notar que al incluir errores de
precisión en la fuerza de tiro ésta desviación disminuye. Ya no es necesario
corregir con ángulos lo que se puede explicar de otra forma, esta correlación la
podemos ver gráficamente por medio de un diagrama de dispersión como abajo.
- $\sigma_f$ tiene un valor esperado de $0.17,$ lo cual implica un error del
17\% debido a la errores en distancia producto de la fuerza de tiro. 
- $\sigma_{\textsf{obs}}$ tiene un valor de $0.03$ lo cual incide en errores
atribuibles a medición del 3 puntos porcentuales.

```{r, echo = FALSE}
color_scheme_set("darkgray")
muestras_sigma <- ajuste$draws(c("sigma_angle", "sigma_force", "sigma_obs"))
mcmc_pairs(muestras_sigma)+ sin_lineas

```
La aparente bimodalidad de los gráficos de dispersión se podría explicar a
traves del efecto de tener mediciones de dos tipos. Un tipo son los datos
originales en los que parece haber un número limitado de registrados, y las
nuevas observaciones de Broadie que tienen un número muy grande observaciones a
distintas distancias.

```{r, echo =  FALSE, message = FALSE, warning = FALSE}
muestras <- tibble(posterior::as_draws_df(ajuste$draws(c("residual"))))
medias <- muestras %>% 
  pivot_longer(cols = starts_with("residual"), names_to = 'parameters', values_to = 'residuals') %>% 
  group_by(parameters) %>% 
  summarise(media = mean(residuals), 
            q_lo = quantile(residuals, 0.05),
            q_hi = quantile(residuals, 0.95), groups = 'drop') %>% 
  mutate(cadena = str_replace_all(parameters, "\\[|\\]", "_")) %>% 
  separate(cadena, into = c("sufijo", "variable"), sep = "_", convert = TRUE) %>% 
  select(media, variable, q_lo, q_hi)

datos %>% 
  mutate(variable = seq(1, nrow(datos))) %>% 
  full_join(medias) %>% 
  ggplot(aes(x = x, y = media)) + 
    geom_linerange(aes(x = x, ymin = q_lo, ymax = q_hi)) + 
    geom_point(aes(color = fuente)) + 
    geom_hline(yintercept = 0, linetype = 'dashed') + 
    ylab('Residuales del modelo ajustado') + 
    xlab('Distancia (cm)') + 
    ggtitle("Modelo con angulo y fuerza de tiro.")+ sin_lineas
```

## Siguientes pasos

- Corregir especificación de modelo.
- Incorporar modelo jerarquico para extraer información de ambos conjuntos de
datos.

## Referencias